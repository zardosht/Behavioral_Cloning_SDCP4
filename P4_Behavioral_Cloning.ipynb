{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Udacity Self-driving Car Nanodegree\n",
    "# Project 4: Behavioral Cloning\n",
    "\n",
    "This project uses CNNs for an end-to-end learning of steering angles from input images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Investigate the Dataset\n",
    "\n",
    "The data set is not included in the project repository and lies on the local file system. The linked folder `driving_data` links to the local folder containing the training data. The file `driving_data/driving_log.csv` contains the labels. The folder `driving_data/IMG/` contains the images. \n",
    "\n",
    "Each row in `driving_log.csv` contains the following CSV values: \n",
    "\n",
    "* center image\n",
    "* left image\n",
    "* right image\n",
    "* steering angles value between `[-1, 1]`. Negative values for steering to left \n",
    "* throttle values between `[0, 1]` (not relevant for this project)\n",
    "* break value all zero (not relevant for this project)\n",
    "* speed values between `[0, 30]` (not relevant for this project)\n",
    "\n",
    "**Camera images** are the **feature set** and the **steering measurements** are the **label set**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_filename(path):\n",
    "   '''\n",
    "   Extract the image filename from the path\n",
    "   ''' \n",
    "   return os.path.basename(path)\n",
    "\n",
    "# Load image file names and labels (steering angles)\n",
    "center_image_names = []\n",
    "left_image_names = []\n",
    "right_image_names = []\n",
    "labels = []\n",
    "\n",
    "dataset_path = \"./driving_data/\"\n",
    "images_path = dataset_path + \"IMG/\"\n",
    "\n",
    "\n",
    "with open(dataset_path + \"driving_log.csv\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        center_image_names.append(get_filename(row[0]))\n",
    "        left_image_names.append(get_filename(row[1]))\n",
    "        right_image_names.append(get_filename(row[2]))\n",
    "        labels.append(float(row[3]))\n",
    "        \n",
    "dataset_size = len(labels)\n",
    "print(\"Dataset size: \", dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random images for the center, left, and right\n",
    "index = random.randint(0, dataset_size)\n",
    "print(\"Index: \", index) # 5632\n",
    "print(\"Steering Angle: \", labels[index])\n",
    "\n",
    "center_img_name = center_image_names[index]\n",
    "print(\"Image name: \", center_img_name)\n",
    "center_img = plt.imread(images_path + center_img_name)\n",
    "left_img = plt.imread(images_path + left_image_names[index])\n",
    "right_img = plt.imread(images_path + right_image_names[index])\n",
    "\n",
    "print(\"Image shape: \", center_img.shape)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 20))\n",
    "ax1.imshow(left_img)\n",
    "ax1.set_title(\"Left Image\")\n",
    "ax2.imshow(center_img)\n",
    "ax2.set_title(\"Center Image\")\n",
    "ax3.imshow(right_img)\n",
    "ax3.set_title(\"Right Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy model pipeline\n",
    "\n",
    "Load the data and train the simplest (linear) model, and save the model in an `.h5` file. \n",
    "\n",
    "Then run the `python derive.py <your_model>`. This starts a server that loads the model and serves its predictions to the incoming requests. \n",
    "\n",
    "When this server is running, start the simulator in *autonomous mode*. The simulator sends images to the model server and gets back the values for steering angle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Flatten, Dense\n",
    "\n",
    "# images = []\n",
    "\n",
    "# for img_name in center_image_names:\n",
    "#     img = plt.imread(images_path + img_name)\n",
    "#     images.append(img)\n",
    "    \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(labels)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(160, 320, 3)))\n",
    "# model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "# model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "# model.save(\"./model/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "This model uses a `Lambda()` layer for preprocessing (normalizing the input) and a `Cropping2D()` layer for cropping the images. \n",
    "\n",
    "The training data also includes the images from left and right camera with the correspondingly corrected steering angel for each view as labels. \n",
    "\n",
    "I also augment the data by flipping the center and inverting its corresponding steering value as label. \n",
    "\n",
    "I start with a LeNet like architecture to see what I get as result. \n",
    "\n",
    "The model uses `generators` to feed the training data bach-wise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "\n",
    "def get_filename(path):\n",
    "   '''\n",
    "   Extract the image filename from the path\n",
    "   ''' \n",
    "   return os.path.basename(path)\n",
    "\n",
    "\n",
    "def generator(samples, images_path, batch_size=32, steering_correction=0.2):\n",
    "    batch_labels = []\n",
    "    batch_images = []\n",
    "    num_samples = len(samples)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            for row in batch_samples:\n",
    "                center_img = plt.imread(images_path + get_filename(row[0]))\n",
    "                center_label = float(row[3])\n",
    "                batch_images.append(center_img)\n",
    "                batch_labels.append(center_label)\n",
    "                \n",
    "                left_img = plt.imread(images_path + get_filename(row[1]))\n",
    "                left_label = center_label + steering_correction\n",
    "                batch_images.append(left_img)\n",
    "                batch_labels.append(left_label)\n",
    "                \n",
    "                right_img = plt.imread(images_path + get_filename(row[2]))\n",
    "                right_label = center_label - steering_correction\n",
    "                batch_images.append(right_img)\n",
    "                batch_labels.append(right_label)\n",
    "                \n",
    "                aug_img = np.fliplr(center_img)\n",
    "                aug_label = -center_label\n",
    "                batch_images.append(aug_img)\n",
    "                batch_labels.append(aug_label)\n",
    "\n",
    "            batch_X = np.array(batch_images)\n",
    "            batch_Y = np.array(batch_labels)\n",
    "            \n",
    "            yield sklearn.utils.shuffle(batch_X, batch_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Cropping2D, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def setup_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # preprocessing cropping and normalizing images\n",
    "    model.add(Cropping2D(cropping=((75, 25), (0, 0)), input_shape=input_shape))\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 1.0))\n",
    "    \n",
    "    model.add(Conv2D(6, (5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation=\"relu\"))\n",
    "    model.add(Dense(84, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"./driving_data/\"\n",
    "images_path = dataset_path + \"IMG/\"\n",
    "\n",
    "# Load the samples from CSV file\n",
    "samples = []\n",
    "with open(dataset_path + \"driving_log.csv\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        samples.append(row)\n",
    "\n",
    "print(\"Number of rows in CSV file: \", len(samples))\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(\"Number of training rows (augmentation and left-right not included): \", len(train_samples))\n",
    "print(\"Number of training samples (augmentation and left-right not included):\", len(train_samples)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "input_shape = (160, 320, 3)\n",
    "model = setup_model(input_shape)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "train_generator = generator(train_samples, images_path)\n",
    "validation_generator = generator(validation_samples, images_path)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "\n",
    "# There len(samples) rows in CSV. Each row has 3 images (center, left, right).\n",
    "# I also add an augmented image. \n",
    "num_train_samples = len(train_samples) * 4\n",
    "num_validation_samples = len(validation_samples) * 4\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"./model/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping()\n",
    "csvlogger = CSVLogger(\"./model/training.log\", separator=\",\", append=False)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=np.ceil(num_train_samples / batch_size), \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=np.ceil(num_validation_samples / batch_size), \n",
    "                    epochs=epochs, verbose=1, \n",
    "                    callbacks=[model_checkpoint, early_stopping, csvlogger])\n",
    "\n",
    "\n",
    "model.save(\"./model/trained/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and Schmierpapier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = np.copy(center_img)\n",
    "red[:, :, 1:] = 0\n",
    "\n",
    "plt.imshow(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(75).reshape(5, 5, 3)\n",
    "b = np.copy(a)\n",
    "c = np.copy(a)\n",
    "d = np.copy(a)\n",
    "\n",
    "b[:, :, 1] = 0\n",
    "b[:, :, 2] = 0\n",
    "print(\"b ------------\")\n",
    "print(b)\n",
    "\n",
    "c[:, :, 1:] = 0\n",
    "print(\"c ------------\")\n",
    "print(c)\n",
    "\n",
    "is_equal = np.all((b == c))\n",
    "print(\"------------\")\n",
    "print(\"b == c: \", is_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/zardosht/Desktop/driving_data/IMG/center_2020_05_03_22_17_31_233.jpg\"\n",
    "basename = os.path.dirname(path)\n",
    "basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "gen = (x for x in range(0, 10))\n",
    "start = 5\n",
    "# stop = start + 4\n",
    "stop = start + 1\n",
    "aslice = itertools.islice(gen, start, stop)\n",
    "aslice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(aslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
